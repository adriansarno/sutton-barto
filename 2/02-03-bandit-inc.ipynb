{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The k-Armed Bandit Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Adrian Sarno\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem definition\n",
    "Givent a slot machine with k arms (a.k.a. k-armed bandit), we want to estimate a function Q that to estimate the expected pay-off of each arm.\n",
    "\n",
    "More formally:\n",
    "\n",
    "                    r = Q[a]\n",
    "where:\n",
    "- Q: value function\n",
    "* a: action (arm pulled)\n",
    "* r: value of the reward (actually, this is the mean value or expectation, since the reward is a random variable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Models Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Models is a matrix of 2000 rows and 10 columns. This matrix contains the expected values that we need to approximate. \n",
    "\n",
    "Each row stores the model parameters of one k-armed bandit (a slot machine with k arms). Each cell in the row stores the True Expected Value of the reward given by each of the k possible actions that the agent can do on the bandit (equivalent to a player pulling one of the k levers). \n",
    "\n",
    "The test models matrix will serve two purposes, one is as generative model, because we will code a simulation that generates examples based on the model parameters stored in the test models matrix.\n",
    "The second purpose is as ground truth to compare to our predicted model against, to measure how precisely we learned the expected values from the generated examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a set of 2000 randomly generated 10-armed bandit models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2000   # number of bandits\n",
    "k = 10     # number of arms in each bandit\n",
    "test_models = np.random.normal(0.0, 1.0, size=(n, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The True Expected Value (arithmetic mean) is a statistic distributed normally with mean 0 and variance 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.03094875, -0.45857274,  2.41666434, -0.71145596, -0.35659632,\n",
       "       -1.01503485, -0.40032631, -1.04028737, -0.07134019, -0.92757493])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a simulation to genete the training examples, the output of the simulation is the reward paid by the bandit when the agent pulls each of the levelrs. This output is stochastic with mean given by the value in the row and column a (action) of the test models matrix, and variance 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the bandit returns the actual reward from the true model\n",
    "def bandit(row, a):\n",
    "    r = test_models[row, a] + np.random.normal()\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action-Value Methods\n",
    "### ε-greedy method - Incremental implementation (Sutton-Barto 2.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greedy action: q∗(At), the action with maximum reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected pay-off Bandit nr. 2=\n",
      "[-0.33688004  1.29815854 -1.01968223  1.34556073  1.40496157  0.17233312\n",
      "  1.05084664  0.51511195  0.67588065  0.6189998 ]\n",
      "\n",
      "Greedy policy:\n",
      "q*: lever=4, expected value=1.4049615703262142\n"
     ]
    }
   ],
   "source": [
    "# greedy action index\n",
    "row = 2\n",
    "q_opt = np.argmax(test_models, 1)  # max along columns (max of each row)\n",
    "print(f\"Expected pay-off Bandit nr. {row}=\\n{test_models[row]}\\n\\nGreedy policy:\\nq*: lever={q_opt[row]}, expected value={test_models[row, q_opt[row]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a greedy method is applied to the 10-armed test models, the algorithm chooses the action mith maximum expected reward, this action is called the greedy action, or action A that maximizes the expected reward.\n",
    "\n",
    "Note that the actual reward is stochastic, the model only knows the Expected reward, and the actual reward is random with q∗(At) as mean (expectation) and variance 1. (where q*() is the greedy policy function, and 'At' is the action at time step t.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ε-greedy method (Sutton-Barto 2.2)\n",
    "def epsilon_greedy(Q, epsilon):\n",
    "    a =  np.random.choice(range(10)) if np.random.sample() < epsilon else np.argmax(Q)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimator of the action values is the averages of the observed rewards for each action.\n",
    "To compute these estimators with minimum computational cost, we apply an incremental formula for updating averages with small, constant computation required to process\n",
    "each new reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_rule(old_estimate, target, step_size):\n",
    "    new_estimate = old_estimate + step_size * (target - old_estimate)\n",
    "    return new_estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smulation and the training process run concurrently, taking one model at a time and generating 1000 simulated plays. In each play, the value function Q (initialized randomly) is used to choose an arm of the bandit, and the reward is used to update the value function, increasing the chances to be selected for those arms that tend to return more positive values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qs = np.zeros(shape=(n, k))\n",
    "num_steps = 1000\n",
    "epsilon = .1\n",
    " \n",
    "# ratio for plotting performance\n",
    "ratio_est_vs_opt = np.zeros(shape=(n, num_steps))\n",
    "# accumulators for plotting performance\n",
    "rewards_accum =   np.zeros(shape=(n, num_steps))\n",
    "opt_rewards_accum =   np.zeros(shape=(n, num_steps)) + 1/10**6 # avoid division by zero at step zero\n",
    "    \n",
    "# for each model\n",
    "for i in range(n):\n",
    "    if i+1 % (n/5) == 0:\n",
    "        print(f\"{i-1} bandits computed\")\n",
    "    \n",
    "    N = np.zeros(k) # action_counters\n",
    "    \n",
    "    # 1 run\n",
    "    for t in range(num_steps):       \n",
    "        # estimate best action, based on estimated action-values, with epsilon-greedy method\n",
    "        a = epsilon_greedy(Qs[i,:], epsilon)\n",
    "        \n",
    "        # act and collect the actual reward from the bandit\n",
    "        reward = bandit(i, a)\n",
    "\n",
    "        # update our estimate of the action value \n",
    "        N[a] += 1\n",
    "        Qs[i, a] = update_rule(Qs[i, a], reward, 1/N[a])\n",
    "              \n",
    "        # store the accumulators to calculate the ratio of epsilon-greedy vs optimal at each step for plotting\n",
    "        if t > 0:\n",
    "            rewards_accum[i, t] = rewards_accum[i, t-1] + reward\n",
    "            opt_rewards_accum[i, t] = opt_rewards_accum[i, t-1] + bandit(i, q_opt[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result we obtain the learned value function (stored in the matrix Qs) and a history of the rewards obtained by the greedy policy according to the value function at each step of the traininng (stored in the matrix rewards_accum). We also compute a history of the rewards that could be obtained at each step if the agent would have known the optimal lever to chose for each banit (this is stored in the opt_rewards_accum matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards_accum.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute ratio of cumulative rewards\n",
    "\n",
    "To compute the ratio, we divide the reward obtained by out learned function q on each bandit at each iteration of the training process (simulation), over the optimal reward of each bandit (stationary) according to the bandit test models matrix.\n",
    "\n",
    "Some bandits in the test models matrix may contain zero or close to zero optimal expected rewards, but if we compute the mean of the optimal expected rewards of all bandits, this will be positive with high probability. Therefore, we compute the means for all bandits first and later compute the ratio of means for each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean along rows (avg of each step over all models)\n",
    "avg_rewards_accum = np.mean(rewards_accum, 0)\n",
    "avg_opt_rewards_accum = np.mean(opt_rewards_accum, 0)\n",
    "\n",
    "#  average performance over all models\n",
    "avg_ratio_est_vs_opt = avg_rewards_accum / avg_opt_rewards_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Ratio Optimal / Model')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_ratio_est_vs_opt)\n",
    "plt.title(\"Training Curve\")\n",
    "plt.xlabel(\"Time (iteration)\")\n",
    "plt.ylabel(\"Ratio Optimal / Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure shows the evolution of the average reward obtained by the gready policy on the Q function as this is being learned over time. We observe that in first few iterations, the ratio is close to zero, showing that the randomly initialized function Q is unable to choose the right arms, but over time Q learns to approximate the value of each arm for each bandit and the ratio between the optimal reward and the reward obtained from the learned value function Q tends to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
